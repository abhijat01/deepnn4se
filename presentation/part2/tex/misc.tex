\section{Miscellaneous topics}

\begin{frame}{Adversarial attacks}
\begin{columns}
	\begin{column}{.5\textwidth}
		\begin{figure}
			\includegraphics[width=1\textwidth]{figures/adverserial-net}
		\end{figure}
	\end{column}
	\begin{column}{.5\textwidth}
		Let $\hat{y}$ be desired,  $y$ be the predicted label, 
		and $\hat{x}$ be the desired image 
		\begin{enumerate}
			\item Simple loss function, $L=D(\hat{y},y)$
			\item Another loss function, $L=D_1(\hat{y},y) + \lambda D_2(\hat{x},x) $
		\end{enumerate}
	\end{column}
\end{columns}
\end{frame}
\begin{frame}{Adversarial examples}
\begin{columns}
\begin{column}{.5\textwidth}
	\begin{figure}
		\includegraphics[width=.8\textwidth]{figures/adverserial-example-1}
		\caption*{\tiny{I. Goodfellow, J. Shlens, and C. Szegedy, Explaining and
				harnessing adversarial examples," in International Conference on Learning Representations, 2015.}}
	\end{figure}
\end{column}
\begin{column}{.5\textwidth}
	\begin{figure}
		\includegraphics[width=1\textwidth]{figures/adverserial-example-2}
		\caption*{\tiny{A. Kurakin, I. Goodfellow, and S. Bengio, Adversarial
				examples in the physical world," ICLR Workshop, 2017.}}
	\end{figure}
	What kinds of attacks can you think of?
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Generative adversarial networks - intuition}
\begin{center}
	\begin{figure}
		\includegraphics[width=1\textwidth]{figures/gan-simple}
	\end{figure}
\end{center}
\end{frame}

\begin{frame}{Attention - intuition} 
\begin{center}
	\begin{figure}
		\includegraphics[width=1\textwidth]{figures/rnn_seq_2_seq_encoder_decoder}
		\caption*{{Sequence to sequence encoder-decoder network}}
	\end{figure}
\end{center}
\end{frame}